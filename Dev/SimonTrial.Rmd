---
title: "stock trial"
author: "Sung Bum Ahn"
date: "4/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(shiny)
library(readr)
library(stringr)
require(quantmod)
library(lubridate)
library(anytime)
library(cluster)    # clustering algorithms
library(factoextra)
library(ggrepel)
library(rvest)
library(httr)
library(tidytext)# clustering algorithms & visualization
```

```{r}
nyse_tickers <- read_csv("data-prep/nyse_tickers.csv")
wsb_dd_submissions <- read_csv("../WSB-viz/www/wsb_dd_submissions.csv")
merged_common <- read_csv("../Dev/data-prep/merged_common.csv")
```

```{r}
nyse_select <- data.frame(str_subset(nyse_tickers$Name, " Common Stock"))

nyse_common <- nyse_tickers %>% 
  inner_join(nyse_select, by = c("Name"="str_subset.nyse_tickers.Name....Common.Stock.."))

nyse_common <- nyse_common %>% 
  mutate(Name = str_replace(Name, " Common Stock", ""))
  
```



```{r}
getQuote("GME;AMC", what=yahooQF("Last Trade (Price Only)"))
```


```{r}
wsb_dd_submissions <- wsb_dd_submissions %>% 
    mutate(ticker=strsplit(title_stocks, " ")) %>% 
    unnest(ticker) %>% 
    drop_na(ticker)
```

```{r}
wsb_dd_submissions <- wsb_dd_submissions %>% 
  mutate(date = anydate(created_utc))
```

```{r}
count_ticker <- wsb_dd_submissions %>% 
  drop_na() %>% 
  group_by(date) %>%
  count(ticker)
```

```{r}
top_10 <- count_ticker %>%
  filter(date >= as.Date("2021-01-01") & date <= as.Date("2021-01-07")) %>%
  group_by(ticker) %>%
  summarise(count = sum(n)) %>%
  arrange(desc(count)) %>%
  slice(1:10)
ggplot(data = top_10, aes(x = ticker, y = count)) +
  geom_col()
```
Page 2

Data Preparation for page 2
```{r}
library(tidyverse)

wsb_dd_submissions <- read_csv("Data/wsb_dd_submissions.csv")

count_and_sent <- function(df){
    
    sentiment_of_stock <- function(ticker){
        filtered_rows <- df%>%
            filter(grepl(ticker, title_stocks))
        print(filtered_rows$title_sentiment)
        return(mean(filtered_rows$title_sentiment))
    }
    stocks <- df$title_stocks[!is.na(df$title_stocks)]
    stocks <- paste(stocks, sep = " ")
    stocks <- as.list(unlist(strsplit(stocks, '[[:space:]]')))
    stocks <- unlist(stocks)
    grouped <- tibble("stock" = stocks) %>%
        group_by(stock) %>%
        summarise(mentions=n())
    grouped$sentiment <- unlist(map(grouped$stock, sentiment_of_stock))
    grouped$sentiment[is.nan(grouped$sentiment)] <- 0 
    return(grouped)
}
    

userSelectDate2 <- wsb_dd_submissions %>%
  mutate(created_utc = strptime(created_utc, format="%s"))%>%
  filter(created_utc >= as.Date("2021-01-01"),
         created_utc <= as.Date("2021-01-05"),
         title_sentiment != 0) %>%
  count_and_sent()
  

userSelectDate2
```

```{r}
sentiment <- userSelectDate2 %>%
  group_by(ticker) %>%
  summarise(sentiment = sum(post_sentiment)) %>% 
  drop_na()

mentionedTimes <- userSelectDate2 %>%
  group_by(date) %>%
  count(ticker) %>% 
  group_by(ticker) %>%
  summarise(count = sum(n))
```

Plot for page 2
```{r}
ggplot(data = kmeanData, aes(x = sentiment, y = count, color = ticker, size = count)) +
  geom_point()
```

```{r}
kmeanDataNum <- kmeanData %>% 
  select(sentiment, count)

df <- kmeanDataNum

df <- na.omit(df)

df <- scale(df)
head(df)
```

kmeans computing and plots
```{r}
?kmeans
glimpse(df)
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
p3

dfc2 <- kmeanData %>%
  mutate(cluster = as.factor(k2$cluster))

  
ggplot(data = dfc2, aes(x = sentiment, y = count, color = cluster)) +
  geom_point() + geom_text_repel(aes(label = ticker), size = 3.5) 
         

set.seed(123)
final <- kmeans(df, 4, nstart = 10)

fviz_cluster(final, data = df)

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

```{r}
pbr <- getSymbols("PBR", src = "yahoo", from = "2013-01-01", to = "2017-06-01", auto.assign = FALSE)
pbr <- read.csv("PBR.csv")
pbr[,1] <- as.Date(pbr[,1])
pbr <- xts(pbr)
pbr <- pbr[,-1]
```


#wordcloud
```{r}

library(wordcloud) 

wsb1 <- wsb_dd_submissions %>%
  select(title_stocks, selftext, created_utc) %>% 
  drop_na() %>% 
  unnest_tokens(word, selftext) %>% 
  filter(word != "https"& word != "removed" & word != "amp" & word != "png" ) %>% 
  mutate(TF = grepl("\\d",word)) %>% 
  filter(TF != TRUE) %>% 
  anti_join(stop_words, by = c("word" = "word")) %>% 
  count(word) %>% 


wordcloud(words = wsb_common_words_by_stock$word, freq = wsb_common_words_by_stock$n, min.freq = 3, max.words=100, random.order=FALSE, rot.per=0.2, colors=brewer.pal(5, "Dark2"))



```


```{r}
        clean_data <- wsb_dd_submissions %>%
            mutate(created_utc = strptime(created_utc, format="%s")) %>%
            filter(created_utc >= as.Date(input$clusterCreateRange[1]),
                   created_utc <= as.Date(input$clusterCreateRange[2])) %>%
            select(title_stocks, selftext, created_utc) %>%
            drop_na() %>%
            unnest_tokens(word, selftext) %>%
            filter(word != "https"& word != "removed" & word != "amp" & word != "png" & word != "jpg" & word != "pjpg" & word != "preview.redd.it" & word != "webp" & word != "auto" & word != "format" & word != "width") %>%
  
            mutate(TF = grepl("\\d",word)) %>%
            filter(TF != TRUE) %>%
            filter(title_stocks == input$StockTicker) %>%
            anti_join(stop_words, by = c("word" = "word")) %>%
            count(word) %>%
            arrange(desc(n)) %>%
            slice(1:100)

```